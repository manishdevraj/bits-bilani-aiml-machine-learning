{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning - Assignment 2 (Semester 1)\n",
        "\n",
        "***************************************************************************\n",
        "BITS ID: **2020AB05241**\n",
        "\n",
        "Name: **Manish Devraj**\n",
        "\n",
        "Email: 2025ab05241@wilp.bits-pilani.ac.in\n",
        "\n",
        "***************************************************************************\n",
        "\n",
        "This notebook compares the following six models for a classification task:\n",
        "1. Logistic Regression\n",
        "2. Decision Tree Classifier\n",
        "3. K-Nearest Neighbor Classifier\n",
        "4. Naive Bayes Classifier\n",
        "5. Random Forest (Ensemble)\n",
        "6. XGBoost (Ensemble)\n",
        "\n",
        "**Dataset**:\\\n",
        "\"Early Stage Diabetes Risk Prediction\" dataset from UCI\n",
        "https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset"
      ],
      "metadata": {
        "id": "BO3CytnfUT14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "thOdpHwDURLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filter_type = \"ignore\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYMkVgfSUYFh",
        "outputId": "d22471fe-dc07-4c70-d2bd-9657abad4dad"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load Dataset"
      ],
      "metadata": {
        "id": "5knyvNriUewN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset\n",
        "early_stage_diabetes_risk_prediction = fetch_ucirepo(id=529)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = early_stage_diabetes_risk_prediction.data.features\n",
        "y = early_stage_diabetes_risk_prediction.data.targets"
      ],
      "metadata": {
        "id": "V1h03_UyMmE9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocessing"
      ],
      "metadata": {
        "id": "0BUXgivHVxRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "\n",
        "if not os.path.exists('model'):\n",
        "    os.makedirs('model')\n",
        "\n",
        "# Encoding target variable\n",
        "le = LabelEncoder()\n",
        "df['target'] = le.fit_transform(df['target'])\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_encoded = pd.get_dummies(df.drop('target', axis=1), drop_first=True)\n",
        "y_encoded = df['target']\n",
        "\n",
        "# Splitting Features and Target\n",
        "X = X_encoded\n",
        "y = y_encoded\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Combine X_test and y_test into a single DataFrame\n",
        "test_df = X_test.copy()\n",
        "test_df['class'] = y_test  # Make sure 'class' matches your actual target column name\n",
        "\n",
        "# Save to CSV\n",
        "test_df.to_csv(\"test_data.csv\", index=False)\n",
        "print(\"✅ test_data.csv created successfully!\")\n",
        "\n",
        "joblib.dump(scaler, 'model/scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PCZmft1Ug1y",
        "outputId": "dd07887a-3ee8-4d24-a4fb-4c7a933cc3ed"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (520, 17)\n",
            "✅ test_data.csv created successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model/scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Training And Implementations"
      ],
      "metadata": {
        "id": "blGV1BaaV60N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "def evaluate_model():\n",
        "    print(\"Training Models...\")\n",
        "    for name, model in models.items():\n",
        "      model.fit(X_train_scaled, y_train)\n",
        "\n",
        "      # Save Model\n",
        "      joblib.dump(model, f'model/{name.replace(\" \", \"_\")}.pkl')\n",
        "\n",
        "      # Predict on the test set for evaluation\n",
        "      y_pred = model.predict(X_test_scaled)\n",
        "      # Calculate Probabilities for AUC (handle models without predict_proba)\n",
        "      if hasattr(model, \"predict_proba\"):\n",
        "          # Check if binary classification (2 classes)\n",
        "          if len(model.classes_) == 2:\n",
        "              y_prob = model.predict_proba(X_test)[:, 1]\n",
        "          else:\n",
        "              y_prob = None # AUC is less relevant for multi-class in this simple view\n",
        "      else:\n",
        "          y_prob = None\n",
        "\n",
        "      # Calculate Metrics\n",
        "      # Note: For multi-class, you may need average='macro' for precision/recall/f1\n",
        "      metrics = {\n",
        "          \"Model name\": name,\n",
        "          \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "          \"AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else 0, # Only calculate AUC if y_prob is available\n",
        "          \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "          \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "          \"F1 Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "          \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "      }\n",
        "      results.append(metrics)\n",
        "\n",
        "      print(f\"Finished evaluating {name}\")\n",
        "\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7FsFVRwV-QT",
        "outputId": "2a237fc6-4cd7-42d8-afc1-7aba16d5495a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Models...\n",
            "Finished evaluating Logistic Regression\n",
            "Finished evaluating Decision Tree\n",
            "Finished evaluating KNN\n",
            "Finished evaluating Naive Bayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:12:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished evaluating Random Forest\n",
            "Finished evaluating XGBoost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Compare models"
      ],
      "metadata": {
        "id": "35cDSWKEWRW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== Evaluation Metrics for README ===\")\n",
        "print(\"\\nComparison Table with the evaluation metrics for all 6 models\\n\")\n",
        "print(results_df)\n",
        "results_df.to_csv(\"model_metrics.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKUp2MmcWXJC",
        "outputId": "9083b12d-39ac-45df-ffe9-ec13470fc0c1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Metrics for README ===\n",
            "\n",
            "Comparison Table with the evaluation metrics for all 6 models\n",
            "\n",
            "            Model name  Accuracy       AUC  Precision    Recall  F1 Score  \\\n",
            "0  Logistic Regression  0.923077  0.558685   0.922533  0.923077  0.922409   \n",
            "1        Decision Tree  0.951923  0.708067   0.958249  0.951923  0.952739   \n",
            "2                  KNN  0.894231  0.652369   0.902167  0.894231  0.896025   \n",
            "3          Naive Bayes  0.913462  0.540333   0.912927  0.913462  0.913098   \n",
            "4        Random Forest  0.990385  0.970551   0.990667  0.990385  0.990422   \n",
            "5              XGBoost  0.971154  0.787452   0.973558  0.971154  0.971470   \n",
            "\n",
            "        MCC  \n",
            "0  0.820358  \n",
            "1  0.898479  \n",
            "2  0.769771  \n",
            "3  0.798823  \n",
            "4  0.978222  \n",
            "5  0.936981  \n"
          ]
        }
      ]
    }
  ]
}